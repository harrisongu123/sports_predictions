{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d9de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9830115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.read_excel('C:\\\\Users\\\\Daniel\\\\Documents\\\\Flatiron\\\\Capstone\\\\sports_predictions\\\\stats.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966cfad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Home Points For</th>\n",
       "      <th>Home Points Against</th>\n",
       "      <th>Home eFG%</th>\n",
       "      <th>Home FTr</th>\n",
       "      <th>Home ORB%</th>\n",
       "      <th>Home DRB%</th>\n",
       "      <th>Home AST%</th>\n",
       "      <th>Home STL%</th>\n",
       "      <th>Home BLK%</th>\n",
       "      <th>Home TOV%</th>\n",
       "      <th>...</th>\n",
       "      <th>Away DRB%</th>\n",
       "      <th>Away AST%</th>\n",
       "      <th>Away STL%</th>\n",
       "      <th>Away BLK%</th>\n",
       "      <th>Away TOV%</th>\n",
       "      <th>Away ORTG</th>\n",
       "      <th>Away DRtg</th>\n",
       "      <th>Away GP</th>\n",
       "      <th>Away Win Rate</th>\n",
       "      <th>Vegas Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.5</td>\n",
       "      <td>117.5</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.230</td>\n",
       "      <td>23.2</td>\n",
       "      <td>75.0</td>\n",
       "      <td>61.9</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>...</td>\n",
       "      <td>76.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>11.9</td>\n",
       "      <td>112.2</td>\n",
       "      <td>111.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108.4</td>\n",
       "      <td>108.2</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.226</td>\n",
       "      <td>21.0</td>\n",
       "      <td>77.2</td>\n",
       "      <td>56.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>12.2</td>\n",
       "      <td>...</td>\n",
       "      <td>78.2</td>\n",
       "      <td>54.9</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>107.9</td>\n",
       "      <td>107.7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.243</td>\n",
       "      <td>24.4</td>\n",
       "      <td>73.3</td>\n",
       "      <td>63.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>14.8</td>\n",
       "      <td>...</td>\n",
       "      <td>79.9</td>\n",
       "      <td>58.9</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>108.4</td>\n",
       "      <td>10</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103.8</td>\n",
       "      <td>111.3</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.294</td>\n",
       "      <td>21.6</td>\n",
       "      <td>76.6</td>\n",
       "      <td>56.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>...</td>\n",
       "      <td>81.4</td>\n",
       "      <td>57.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>110.7</td>\n",
       "      <td>109.8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109.7</td>\n",
       "      <td>114.2</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.180</td>\n",
       "      <td>27.0</td>\n",
       "      <td>77.9</td>\n",
       "      <td>60.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>...</td>\n",
       "      <td>78.0</td>\n",
       "      <td>63.9</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>12.5</td>\n",
       "      <td>109.4</td>\n",
       "      <td>107.6</td>\n",
       "      <td>10</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.1</td>\n",
       "      <td>106.7</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.241</td>\n",
       "      <td>21.4</td>\n",
       "      <td>75.7</td>\n",
       "      <td>56.4</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>13.8</td>\n",
       "      <td>...</td>\n",
       "      <td>76.2</td>\n",
       "      <td>56.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>12.6</td>\n",
       "      <td>109.8</td>\n",
       "      <td>110.3</td>\n",
       "      <td>12</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100.5</td>\n",
       "      <td>111.9</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.201</td>\n",
       "      <td>25.6</td>\n",
       "      <td>78.4</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>78.5</td>\n",
       "      <td>62.3</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14.3</td>\n",
       "      <td>106.7</td>\n",
       "      <td>103.5</td>\n",
       "      <td>12</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110.0</td>\n",
       "      <td>107.9</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.185</td>\n",
       "      <td>20.6</td>\n",
       "      <td>77.3</td>\n",
       "      <td>64.6</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>11.4</td>\n",
       "      <td>...</td>\n",
       "      <td>79.6</td>\n",
       "      <td>54.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12.1</td>\n",
       "      <td>105.3</td>\n",
       "      <td>108.4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>101.8</td>\n",
       "      <td>98.5</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.180</td>\n",
       "      <td>20.5</td>\n",
       "      <td>80.2</td>\n",
       "      <td>59.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>14.1</td>\n",
       "      <td>...</td>\n",
       "      <td>113.2</td>\n",
       "      <td>56.2</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>11.8</td>\n",
       "      <td>109.1</td>\n",
       "      <td>113.2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>115.9</td>\n",
       "      <td>102.3</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.233</td>\n",
       "      <td>22.4</td>\n",
       "      <td>81.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>10.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>78.5</td>\n",
       "      <td>56.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>111.7</td>\n",
       "      <td>104.3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>112.3</td>\n",
       "      <td>112.8</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.219</td>\n",
       "      <td>21.8</td>\n",
       "      <td>75.0</td>\n",
       "      <td>57.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>14.5</td>\n",
       "      <td>...</td>\n",
       "      <td>68.9</td>\n",
       "      <td>62.1</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>104.1</td>\n",
       "      <td>109.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Home Points For  Home Points Against  Home eFG%  Home FTr  Home ORB%  \\\n",
       "0             114.5                117.5      0.519     0.230       23.2   \n",
       "1             108.4                108.2      0.502     0.226       21.0   \n",
       "2             105.0                104.3      0.525     0.243       24.4   \n",
       "3             103.8                111.3      0.512     0.294       21.6   \n",
       "4             109.7                114.2      0.508     0.180       27.0   \n",
       "5              99.1                106.7      0.473     0.241       21.4   \n",
       "6             100.5                111.9      0.474     0.201       25.6   \n",
       "7             110.0                107.9      0.523     0.185       20.6   \n",
       "8             101.8                 98.5      0.523     0.180       20.5   \n",
       "9             115.9                102.3      0.560     0.233       22.4   \n",
       "10            112.3                112.8      0.532     0.219       21.8   \n",
       "\n",
       "    Home DRB%  Home AST%  Home STL%  Home BLK%  Home TOV%  ...  Away DRB%  \\\n",
       "0        75.0       61.9        9.5        4.9       11.7  ...       76.5   \n",
       "1        77.2       56.9        8.5        6.5       12.2  ...       78.2   \n",
       "2        73.3       63.3        7.6        3.7       14.8  ...       79.9   \n",
       "3        76.6       56.4        8.3        4.4       16.9  ...       81.4   \n",
       "4        77.9       60.8       10.5        5.9       12.4  ...       78.0   \n",
       "5        75.7       56.4        7.1        4.1       13.8  ...       76.2   \n",
       "6        78.4       62.0        7.7        4.4       13.9  ...       78.5   \n",
       "7        77.3       64.6        9.4        5.8       11.4  ...       79.6   \n",
       "8        80.2       59.1        8.5        4.4       14.1  ...      113.2   \n",
       "9        81.1       70.7       10.5        4.8       13.9  ...       78.5   \n",
       "10       75.0       57.2        8.8        6.2       14.5  ...       68.9   \n",
       "\n",
       "    Away AST%  Away STL%  Away BLK%  Away TOV%  Away ORTG  Away DRtg  Away GP  \\\n",
       "0        55.5        7.5        6.3       11.9      112.2      111.0       12   \n",
       "1        54.9        7.6        4.5       12.5      107.9      107.7       12   \n",
       "2        58.9        8.6        5.1       13.4       98.0      108.4       10   \n",
       "3        57.5        8.0        4.8       12.5      110.7      109.8       12   \n",
       "4        63.9        8.9        4.8       12.5      109.4      107.6       10   \n",
       "5        56.1        6.9        5.1       12.6      109.8      110.3       12   \n",
       "6        62.3        6.3        5.5       14.3      106.7      103.5       12   \n",
       "7        54.9        6.9        4.5       12.1      105.3      108.4       11   \n",
       "8        56.2        6.8        3.7       11.8      109.1      113.2       12   \n",
       "9        56.9        8.8        5.1       11.3      111.7      104.3       11   \n",
       "10       62.1        9.6        5.9       14.6      104.1      109.0       10   \n",
       "\n",
       "    Away Win Rate  Vegas Prediction  \n",
       "0        0.833333              -1.5  \n",
       "1        0.714286              -1.0  \n",
       "2        0.200000               4.5  \n",
       "3        0.000000              -6.5  \n",
       "4        0.670000              -2.0  \n",
       "5        0.500000              -4.5  \n",
       "6        0.670000              -9.0  \n",
       "7        0.400000              -2.5  \n",
       "8        0.125000               4.0  \n",
       "9        0.750000               5.5  \n",
       "10       0.330000               2.0  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe4b76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('avg_by_game')\n",
    "odds = pd.read_csv('nba_game_odds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b0f9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.set_index(df['Unnamed: 0'], drop=True)\n",
    "data.index.rename('GameID', inplace=True)\n",
    "data.drop(columns='Unnamed: 0', inplace=True)\n",
    "\n",
    "odds.set_index(odds['GameID'], drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a64e7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_index(inplace=True)\n",
    "odds.sort_index(inplace=True)\n",
    "data['Home Wins By (Vegas)'] = odds['Home Win By (Vegas)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0aecc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-3759b8bb49ca>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Home Wins By (Vegas)'][i] = odds['Home Win By (Vegas)'][i]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data['Home Wins By (Vegas)'][i] = odds['Home Win By (Vegas)'][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082689b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(columns=['linreg', 'forest', 'gb', 'NN', 'Vegas Prediction'],\n",
    "                      index = range(len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c123fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.drop(columns='Home Win By')\n",
    "y = data['Home Win By']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cb4ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "forest = RandomForestRegressor(max_depth=10, min_samples_leaf=3, min_samples_split=3, n_estimators=200)\n",
    "gb = GradientBoostingRegressor(learning_rate=0.2, max_depth=1, min_samples_leaf=5, min_samples_split=3, n_estimators=200, random_state=42)\n",
    "ml_models = [linreg, forest, gb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63bb596a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(x, y, x_test, model):\n",
    "\n",
    "    model.fit(x, y)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    \n",
    "    return y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c597ca8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = models.Sequential()\n",
    "nn.add(Dense(500, input_dim=29, activation= 'relu'))\n",
    "nn.add(Dense(250, activation= 'relu'))\n",
    "nn.add(Dense(125, activation= 'relu'))\n",
    "\n",
    "nn.add(Dense(1, activation='linear'))\n",
    "\n",
    "nn.compile(loss='mse', optimizer='adam', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a85a69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "39/39 - 1s - loss: 239.9442 - mean_squared_error: 239.9442\n",
      "Epoch 2/200\n",
      "39/39 - 0s - loss: 142.9162 - mean_squared_error: 142.9162\n",
      "Epoch 3/200\n",
      "39/39 - 0s - loss: 132.3006 - mean_squared_error: 132.3006\n",
      "Epoch 4/200\n",
      "39/39 - 0s - loss: 133.6733 - mean_squared_error: 133.6733\n",
      "Epoch 5/200\n",
      "39/39 - 0s - loss: 135.3154 - mean_squared_error: 135.3154\n",
      "Epoch 6/200\n",
      "39/39 - 0s - loss: 130.4439 - mean_squared_error: 130.4439\n",
      "Epoch 7/200\n",
      "39/39 - 0s - loss: 129.8885 - mean_squared_error: 129.8885\n",
      "Epoch 8/200\n",
      "39/39 - 0s - loss: 129.2193 - mean_squared_error: 129.2193\n",
      "Epoch 9/200\n",
      "39/39 - 0s - loss: 129.8159 - mean_squared_error: 129.8159\n",
      "Epoch 10/200\n",
      "39/39 - 0s - loss: 131.7289 - mean_squared_error: 131.7289\n",
      "Epoch 11/200\n",
      "39/39 - 0s - loss: 130.1725 - mean_squared_error: 130.1725\n",
      "Epoch 12/200\n",
      "39/39 - 0s - loss: 128.1828 - mean_squared_error: 128.1828\n",
      "Epoch 13/200\n",
      "39/39 - 0s - loss: 127.7758 - mean_squared_error: 127.7758\n",
      "Epoch 14/200\n",
      "39/39 - 0s - loss: 128.2872 - mean_squared_error: 128.2872\n",
      "Epoch 15/200\n",
      "39/39 - 0s - loss: 132.6295 - mean_squared_error: 132.6295\n",
      "Epoch 16/200\n",
      "39/39 - 0s - loss: 128.2802 - mean_squared_error: 128.2802\n",
      "Epoch 17/200\n",
      "39/39 - 0s - loss: 128.1913 - mean_squared_error: 128.1913\n",
      "Epoch 18/200\n",
      "39/39 - 0s - loss: 129.6048 - mean_squared_error: 129.6048\n",
      "Epoch 19/200\n",
      "39/39 - 0s - loss: 127.2390 - mean_squared_error: 127.2390\n",
      "Epoch 20/200\n",
      "39/39 - 0s - loss: 133.2838 - mean_squared_error: 133.2838\n",
      "Epoch 21/200\n",
      "39/39 - 0s - loss: 129.7133 - mean_squared_error: 129.7133\n",
      "Epoch 22/200\n",
      "39/39 - 0s - loss: 130.1438 - mean_squared_error: 130.1438\n",
      "Epoch 23/200\n",
      "39/39 - 0s - loss: 126.7673 - mean_squared_error: 126.7673\n",
      "Epoch 24/200\n",
      "39/39 - 0s - loss: 129.3975 - mean_squared_error: 129.3975\n",
      "Epoch 25/200\n",
      "39/39 - 0s - loss: 127.5195 - mean_squared_error: 127.5195\n",
      "Epoch 26/200\n",
      "39/39 - 0s - loss: 128.4115 - mean_squared_error: 128.4115\n",
      "Epoch 27/200\n",
      "39/39 - 0s - loss: 127.2720 - mean_squared_error: 127.2720\n",
      "Epoch 28/200\n",
      "39/39 - 0s - loss: 127.1516 - mean_squared_error: 127.1516\n",
      "Epoch 29/200\n",
      "39/39 - 0s - loss: 127.6049 - mean_squared_error: 127.6049\n",
      "Epoch 30/200\n",
      "39/39 - 0s - loss: 127.6903 - mean_squared_error: 127.6903\n",
      "Epoch 31/200\n",
      "39/39 - 0s - loss: 127.6624 - mean_squared_error: 127.6624\n",
      "Epoch 32/200\n",
      "39/39 - 0s - loss: 127.6518 - mean_squared_error: 127.6518\n",
      "Epoch 33/200\n",
      "39/39 - 0s - loss: 128.3427 - mean_squared_error: 128.3427\n",
      "Epoch 34/200\n",
      "39/39 - 0s - loss: 126.3315 - mean_squared_error: 126.3315\n",
      "Epoch 35/200\n",
      "39/39 - 0s - loss: 129.0363 - mean_squared_error: 129.0363\n",
      "Epoch 36/200\n",
      "39/39 - 0s - loss: 127.7007 - mean_squared_error: 127.7007\n",
      "Epoch 37/200\n",
      "39/39 - 0s - loss: 125.5488 - mean_squared_error: 125.5488\n",
      "Epoch 38/200\n",
      "39/39 - 0s - loss: 126.5032 - mean_squared_error: 126.5032\n",
      "Epoch 39/200\n",
      "39/39 - 0s - loss: 126.7712 - mean_squared_error: 126.7712\n",
      "Epoch 40/200\n",
      "39/39 - 0s - loss: 130.0257 - mean_squared_error: 130.0257\n",
      "Epoch 41/200\n",
      "39/39 - 0s - loss: 129.2481 - mean_squared_error: 129.2480\n",
      "Epoch 42/200\n",
      "39/39 - 0s - loss: 126.1570 - mean_squared_error: 126.1570\n",
      "Epoch 43/200\n",
      "39/39 - 0s - loss: 127.5649 - mean_squared_error: 127.5649\n",
      "Epoch 44/200\n",
      "39/39 - 0s - loss: 127.0008 - mean_squared_error: 127.0008\n",
      "Epoch 45/200\n",
      "39/39 - 0s - loss: 127.1827 - mean_squared_error: 127.1827\n",
      "Epoch 46/200\n",
      "39/39 - 0s - loss: 128.8433 - mean_squared_error: 128.8433\n",
      "Epoch 47/200\n",
      "39/39 - 0s - loss: 125.8776 - mean_squared_error: 125.8776\n",
      "Epoch 48/200\n",
      "39/39 - 0s - loss: 127.0879 - mean_squared_error: 127.0879\n",
      "Epoch 49/200\n",
      "39/39 - 0s - loss: 125.8487 - mean_squared_error: 125.8487\n",
      "Epoch 50/200\n",
      "39/39 - 0s - loss: 125.8234 - mean_squared_error: 125.8234\n",
      "Epoch 51/200\n",
      "39/39 - 0s - loss: 125.8718 - mean_squared_error: 125.8718\n",
      "Epoch 52/200\n",
      "39/39 - 0s - loss: 126.5271 - mean_squared_error: 126.5271\n",
      "Epoch 53/200\n",
      "39/39 - 0s - loss: 125.9527 - mean_squared_error: 125.9527\n",
      "Epoch 54/200\n",
      "39/39 - 0s - loss: 125.9896 - mean_squared_error: 125.9896\n",
      "Epoch 55/200\n",
      "39/39 - 0s - loss: 125.4165 - mean_squared_error: 125.4165\n",
      "Epoch 56/200\n",
      "39/39 - 0s - loss: 125.5206 - mean_squared_error: 125.5206\n",
      "Epoch 57/200\n",
      "39/39 - 0s - loss: 126.7430 - mean_squared_error: 126.7430\n",
      "Epoch 58/200\n",
      "39/39 - 0s - loss: 127.3190 - mean_squared_error: 127.3190\n",
      "Epoch 59/200\n",
      "39/39 - 0s - loss: 127.4205 - mean_squared_error: 127.4205\n",
      "Epoch 60/200\n",
      "39/39 - 0s - loss: 126.3131 - mean_squared_error: 126.3131\n",
      "Epoch 61/200\n",
      "39/39 - 0s - loss: 127.5961 - mean_squared_error: 127.5961\n",
      "Epoch 62/200\n",
      "39/39 - 0s - loss: 127.4774 - mean_squared_error: 127.4774\n",
      "Epoch 63/200\n",
      "39/39 - 0s - loss: 130.7673 - mean_squared_error: 130.7673\n",
      "Epoch 64/200\n",
      "39/39 - 0s - loss: 126.0531 - mean_squared_error: 126.0531\n",
      "Epoch 65/200\n",
      "39/39 - 0s - loss: 126.0124 - mean_squared_error: 126.0124\n",
      "Epoch 66/200\n",
      "39/39 - 0s - loss: 126.5650 - mean_squared_error: 126.5650\n",
      "Epoch 67/200\n",
      "39/39 - 0s - loss: 126.1021 - mean_squared_error: 126.1021\n",
      "Epoch 68/200\n",
      "39/39 - 0s - loss: 125.3086 - mean_squared_error: 125.3086\n",
      "Epoch 69/200\n",
      "39/39 - 0s - loss: 127.6427 - mean_squared_error: 127.6427\n",
      "Epoch 70/200\n",
      "39/39 - 0s - loss: 126.7998 - mean_squared_error: 126.7998\n",
      "Epoch 71/200\n",
      "39/39 - 0s - loss: 126.4299 - mean_squared_error: 126.4299\n",
      "Epoch 72/200\n",
      "39/39 - 0s - loss: 126.3647 - mean_squared_error: 126.3647\n",
      "Epoch 73/200\n",
      "39/39 - 0s - loss: 125.8471 - mean_squared_error: 125.8471\n",
      "Epoch 74/200\n",
      "39/39 - 0s - loss: 127.4331 - mean_squared_error: 127.4331\n",
      "Epoch 75/200\n",
      "39/39 - 0s - loss: 125.5476 - mean_squared_error: 125.5476\n",
      "Epoch 76/200\n",
      "39/39 - 0s - loss: 126.8533 - mean_squared_error: 126.8533\n",
      "Epoch 77/200\n",
      "39/39 - 0s - loss: 129.1129 - mean_squared_error: 129.1129\n",
      "Epoch 78/200\n",
      "39/39 - 0s - loss: 127.6397 - mean_squared_error: 127.6397\n",
      "Epoch 79/200\n",
      "39/39 - 0s - loss: 125.2076 - mean_squared_error: 125.2076\n",
      "Epoch 80/200\n",
      "39/39 - 0s - loss: 124.9989 - mean_squared_error: 124.9989\n",
      "Epoch 81/200\n",
      "39/39 - 0s - loss: 125.8769 - mean_squared_error: 125.8769\n",
      "Epoch 82/200\n",
      "39/39 - 0s - loss: 126.2532 - mean_squared_error: 126.2532\n",
      "Epoch 83/200\n",
      "39/39 - 0s - loss: 126.1322 - mean_squared_error: 126.1322\n",
      "Epoch 84/200\n",
      "39/39 - 0s - loss: 127.7167 - mean_squared_error: 127.7167\n",
      "Epoch 85/200\n",
      "39/39 - 0s - loss: 130.2229 - mean_squared_error: 130.2229\n",
      "Epoch 86/200\n",
      "39/39 - 0s - loss: 127.4201 - mean_squared_error: 127.4202\n",
      "Epoch 87/200\n",
      "39/39 - 0s - loss: 126.8133 - mean_squared_error: 126.8133\n",
      "Epoch 88/200\n",
      "39/39 - 0s - loss: 126.3170 - mean_squared_error: 126.3170\n",
      "Epoch 89/200\n",
      "39/39 - 0s - loss: 125.7363 - mean_squared_error: 125.7363\n",
      "Epoch 90/200\n",
      "39/39 - 0s - loss: 126.8646 - mean_squared_error: 126.8646\n",
      "Epoch 91/200\n",
      "39/39 - 0s - loss: 126.1113 - mean_squared_error: 126.1113\n",
      "Epoch 92/200\n",
      "39/39 - 0s - loss: 125.9954 - mean_squared_error: 125.9954\n",
      "Epoch 93/200\n",
      "39/39 - 0s - loss: 128.3279 - mean_squared_error: 128.3279\n",
      "Epoch 94/200\n",
      "39/39 - 0s - loss: 127.6167 - mean_squared_error: 127.6167\n",
      "Epoch 95/200\n",
      "39/39 - 0s - loss: 125.1899 - mean_squared_error: 125.1899\n",
      "Epoch 96/200\n",
      "39/39 - 0s - loss: 124.7418 - mean_squared_error: 124.7418\n",
      "Epoch 97/200\n",
      "39/39 - 0s - loss: 124.9232 - mean_squared_error: 124.9232\n",
      "Epoch 98/200\n",
      "39/39 - 0s - loss: 125.5126 - mean_squared_error: 125.5126\n",
      "Epoch 99/200\n",
      "39/39 - 0s - loss: 125.8825 - mean_squared_error: 125.8825\n",
      "Epoch 100/200\n",
      "39/39 - 0s - loss: 126.1150 - mean_squared_error: 126.1150\n",
      "Epoch 101/200\n",
      "39/39 - 0s - loss: 125.9656 - mean_squared_error: 125.9656\n",
      "Epoch 102/200\n",
      "39/39 - 0s - loss: 126.4299 - mean_squared_error: 126.4299\n",
      "Epoch 103/200\n",
      "39/39 - 0s - loss: 126.7719 - mean_squared_error: 126.7719\n",
      "Epoch 104/200\n",
      "39/39 - 0s - loss: 127.6439 - mean_squared_error: 127.6439\n",
      "Epoch 105/200\n",
      "39/39 - 0s - loss: 125.0093 - mean_squared_error: 125.0093\n",
      "Epoch 106/200\n",
      "39/39 - 0s - loss: 125.8712 - mean_squared_error: 125.8712\n",
      "Epoch 107/200\n",
      "39/39 - 0s - loss: 126.5321 - mean_squared_error: 126.5321\n",
      "Epoch 108/200\n",
      "39/39 - 0s - loss: 124.9248 - mean_squared_error: 124.9248\n",
      "Epoch 109/200\n",
      "39/39 - 0s - loss: 126.0119 - mean_squared_error: 126.0119\n",
      "Epoch 110/200\n",
      "39/39 - 0s - loss: 127.5606 - mean_squared_error: 127.5606\n",
      "Epoch 111/200\n",
      "39/39 - 0s - loss: 125.1742 - mean_squared_error: 125.1742\n",
      "Epoch 112/200\n",
      "39/39 - 0s - loss: 125.0497 - mean_squared_error: 125.0497\n",
      "Epoch 113/200\n",
      "39/39 - 0s - loss: 127.8516 - mean_squared_error: 127.8516\n",
      "Epoch 114/200\n",
      "39/39 - 0s - loss: 124.8319 - mean_squared_error: 124.8319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "39/39 - 0s - loss: 124.8036 - mean_squared_error: 124.8036\n",
      "Epoch 116/200\n",
      "39/39 - 0s - loss: 124.5866 - mean_squared_error: 124.5866\n",
      "Epoch 117/200\n",
      "39/39 - 0s - loss: 126.1606 - mean_squared_error: 126.1606\n",
      "Epoch 118/200\n",
      "39/39 - 0s - loss: 125.6372 - mean_squared_error: 125.6372\n",
      "Epoch 119/200\n",
      "39/39 - 0s - loss: 124.5519 - mean_squared_error: 124.5519\n",
      "Epoch 120/200\n",
      "39/39 - 0s - loss: 124.7294 - mean_squared_error: 124.7294\n",
      "Epoch 121/200\n",
      "39/39 - 0s - loss: 127.0800 - mean_squared_error: 127.0800\n",
      "Epoch 122/200\n",
      "39/39 - 0s - loss: 127.7427 - mean_squared_error: 127.7427\n",
      "Epoch 123/200\n",
      "39/39 - 0s - loss: 125.7402 - mean_squared_error: 125.7402\n",
      "Epoch 124/200\n",
      "39/39 - 0s - loss: 125.2069 - mean_squared_error: 125.2069\n",
      "Epoch 125/200\n",
      "39/39 - 0s - loss: 126.2737 - mean_squared_error: 126.2737\n",
      "Epoch 126/200\n",
      "39/39 - 0s - loss: 126.2484 - mean_squared_error: 126.2484\n",
      "Epoch 127/200\n",
      "39/39 - 0s - loss: 124.6292 - mean_squared_error: 124.6292\n",
      "Epoch 128/200\n",
      "39/39 - 0s - loss: 124.6143 - mean_squared_error: 124.6143\n",
      "Epoch 129/200\n",
      "39/39 - 0s - loss: 124.8656 - mean_squared_error: 124.8656\n",
      "Epoch 130/200\n",
      "39/39 - 0s - loss: 125.3343 - mean_squared_error: 125.3343\n",
      "Epoch 131/200\n",
      "39/39 - 0s - loss: 126.8687 - mean_squared_error: 126.8687\n",
      "Epoch 132/200\n",
      "39/39 - 0s - loss: 126.4337 - mean_squared_error: 126.4337\n",
      "Epoch 133/200\n",
      "39/39 - 0s - loss: 124.8181 - mean_squared_error: 124.8181\n",
      "Epoch 134/200\n",
      "39/39 - 0s - loss: 125.9589 - mean_squared_error: 125.9589\n",
      "Epoch 135/200\n",
      "39/39 - 0s - loss: 126.7873 - mean_squared_error: 126.7873\n",
      "Epoch 136/200\n",
      "39/39 - 0s - loss: 124.5819 - mean_squared_error: 124.5819\n",
      "Epoch 137/200\n",
      "39/39 - 0s - loss: 126.4892 - mean_squared_error: 126.4892\n",
      "Epoch 138/200\n",
      "39/39 - 0s - loss: 126.0315 - mean_squared_error: 126.0315\n",
      "Epoch 139/200\n",
      "39/39 - 0s - loss: 126.2443 - mean_squared_error: 126.2443\n",
      "Epoch 140/200\n",
      "39/39 - 0s - loss: 124.9676 - mean_squared_error: 124.9676\n",
      "Epoch 141/200\n",
      "39/39 - 0s - loss: 124.8845 - mean_squared_error: 124.8845\n",
      "Epoch 142/200\n",
      "39/39 - 0s - loss: 124.1328 - mean_squared_error: 124.1328\n",
      "Epoch 143/200\n",
      "39/39 - 0s - loss: 124.0946 - mean_squared_error: 124.0946\n",
      "Epoch 144/200\n",
      "39/39 - 0s - loss: 124.7493 - mean_squared_error: 124.7493\n",
      "Epoch 145/200\n",
      "39/39 - 0s - loss: 126.1850 - mean_squared_error: 126.1850\n",
      "Epoch 146/200\n",
      "39/39 - 0s - loss: 124.0576 - mean_squared_error: 124.0576\n",
      "Epoch 147/200\n",
      "39/39 - 0s - loss: 123.9777 - mean_squared_error: 123.9777\n",
      "Epoch 148/200\n",
      "39/39 - 0s - loss: 124.4942 - mean_squared_error: 124.4942\n",
      "Epoch 149/200\n",
      "39/39 - 0s - loss: 128.5339 - mean_squared_error: 128.5339\n",
      "Epoch 150/200\n",
      "39/39 - 0s - loss: 125.9456 - mean_squared_error: 125.9456\n",
      "Epoch 151/200\n",
      "39/39 - 0s - loss: 124.6188 - mean_squared_error: 124.6188\n",
      "Epoch 152/200\n",
      "39/39 - 0s - loss: 125.1409 - mean_squared_error: 125.1409\n",
      "Epoch 153/200\n",
      "39/39 - 0s - loss: 124.3714 - mean_squared_error: 124.3714\n",
      "Epoch 154/200\n",
      "39/39 - 0s - loss: 125.3029 - mean_squared_error: 125.3029\n",
      "Epoch 155/200\n",
      "39/39 - 0s - loss: 125.6604 - mean_squared_error: 125.6604\n",
      "Epoch 156/200\n",
      "39/39 - 0s - loss: 124.7079 - mean_squared_error: 124.7079\n",
      "Epoch 157/200\n",
      "39/39 - 0s - loss: 124.1037 - mean_squared_error: 124.1037\n",
      "Epoch 158/200\n",
      "39/39 - 0s - loss: 124.3867 - mean_squared_error: 124.3867\n",
      "Epoch 159/200\n",
      "39/39 - 0s - loss: 124.4990 - mean_squared_error: 124.4990\n",
      "Epoch 160/200\n",
      "39/39 - 0s - loss: 124.9011 - mean_squared_error: 124.9011\n",
      "Epoch 161/200\n",
      "39/39 - 0s - loss: 125.0942 - mean_squared_error: 125.0942\n",
      "Epoch 162/200\n",
      "39/39 - 0s - loss: 124.6390 - mean_squared_error: 124.6390\n",
      "Epoch 163/200\n",
      "39/39 - 0s - loss: 123.9617 - mean_squared_error: 123.9617\n",
      "Epoch 164/200\n",
      "39/39 - 0s - loss: 123.9802 - mean_squared_error: 123.9802\n",
      "Epoch 165/200\n",
      "39/39 - 0s - loss: 125.0355 - mean_squared_error: 125.0355\n",
      "Epoch 166/200\n",
      "39/39 - 0s - loss: 123.9883 - mean_squared_error: 123.9883\n",
      "Epoch 167/200\n",
      "39/39 - 0s - loss: 125.0388 - mean_squared_error: 125.0388\n",
      "Epoch 168/200\n",
      "39/39 - 0s - loss: 124.7149 - mean_squared_error: 124.7149\n",
      "Epoch 169/200\n",
      "39/39 - 0s - loss: 125.2710 - mean_squared_error: 125.2710\n",
      "Epoch 170/200\n",
      "39/39 - 0s - loss: 124.9267 - mean_squared_error: 124.9267\n",
      "Epoch 171/200\n",
      "39/39 - 0s - loss: 125.5883 - mean_squared_error: 125.5883\n",
      "Epoch 172/200\n",
      "39/39 - 0s - loss: 125.0960 - mean_squared_error: 125.0960\n",
      "Epoch 173/200\n",
      "39/39 - 0s - loss: 125.5537 - mean_squared_error: 125.5537\n",
      "Epoch 174/200\n",
      "39/39 - 0s - loss: 123.5534 - mean_squared_error: 123.5534\n",
      "Epoch 175/200\n",
      "39/39 - 0s - loss: 124.4694 - mean_squared_error: 124.4694\n",
      "Epoch 176/200\n",
      "39/39 - 0s - loss: 124.3091 - mean_squared_error: 124.3091\n",
      "Epoch 177/200\n",
      "39/39 - 0s - loss: 124.6677 - mean_squared_error: 124.6677\n",
      "Epoch 178/200\n",
      "39/39 - 0s - loss: 124.2589 - mean_squared_error: 124.2589\n",
      "Epoch 179/200\n",
      "39/39 - 0s - loss: 125.0929 - mean_squared_error: 125.0929\n",
      "Epoch 180/200\n",
      "39/39 - 0s - loss: 125.9808 - mean_squared_error: 125.9808\n",
      "Epoch 181/200\n",
      "39/39 - 0s - loss: 125.6734 - mean_squared_error: 125.6734\n",
      "Epoch 182/200\n",
      "39/39 - 0s - loss: 124.1060 - mean_squared_error: 124.1060\n",
      "Epoch 183/200\n",
      "39/39 - 0s - loss: 125.9289 - mean_squared_error: 125.9289\n",
      "Epoch 184/200\n",
      "39/39 - 0s - loss: 123.8460 - mean_squared_error: 123.8460\n",
      "Epoch 185/200\n",
      "39/39 - 0s - loss: 123.6682 - mean_squared_error: 123.6682\n",
      "Epoch 186/200\n",
      "39/39 - 0s - loss: 124.8578 - mean_squared_error: 124.8578\n",
      "Epoch 187/200\n",
      "39/39 - 0s - loss: 127.1460 - mean_squared_error: 127.1460\n",
      "Epoch 188/200\n",
      "39/39 - 0s - loss: 124.7107 - mean_squared_error: 124.7107\n",
      "Epoch 189/200\n",
      "39/39 - 0s - loss: 124.3284 - mean_squared_error: 124.3284\n",
      "Epoch 190/200\n",
      "39/39 - 0s - loss: 125.2021 - mean_squared_error: 125.2021\n",
      "Epoch 191/200\n",
      "39/39 - 0s - loss: 123.9679 - mean_squared_error: 123.9679\n",
      "Epoch 192/200\n",
      "39/39 - 0s - loss: 124.4329 - mean_squared_error: 124.4329\n",
      "Epoch 193/200\n",
      "39/39 - 0s - loss: 123.8517 - mean_squared_error: 123.8517\n",
      "Epoch 194/200\n",
      "39/39 - 0s - loss: 123.1828 - mean_squared_error: 123.1828\n",
      "Epoch 195/200\n",
      "39/39 - 0s - loss: 124.1135 - mean_squared_error: 124.1135\n",
      "Epoch 196/200\n",
      "39/39 - 0s - loss: 123.7555 - mean_squared_error: 123.7555\n",
      "Epoch 197/200\n",
      "39/39 - 0s - loss: 123.1157 - mean_squared_error: 123.1157\n",
      "Epoch 198/200\n",
      "39/39 - 0s - loss: 124.1597 - mean_squared_error: 124.1597\n",
      "Epoch 199/200\n",
      "39/39 - 0s - loss: 128.3041 - mean_squared_error: 128.3041\n",
      "Epoch 200/200\n",
      "39/39 - 0s - loss: 123.8692 - mean_squared_error: 123.8692\n"
     ]
    }
   ],
   "source": [
    "nn.fit(x, y, epochs=200, verbose=2, batch_size=300)\n",
    "test_preds = nn.predict(x_test)\n",
    "results['NN'] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed7e68a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = ['linreg', 'forest', 'gb', 'NN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c46a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(ml_models):\n",
    "    preds = run_model(x, y, x_test, model)\n",
    "    results[column_names[i]] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b8ac2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results['Vegas Prediction'] = x_test['Vegas Prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b7f089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>linreg</th>\n",
       "      <th>forest</th>\n",
       "      <th>gb</th>\n",
       "      <th>NN</th>\n",
       "      <th>Vegas Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.937607</td>\n",
       "      <td>-7.707503</td>\n",
       "      <td>-5.952967</td>\n",
       "      <td>-3.557056</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.119679</td>\n",
       "      <td>-7.025503</td>\n",
       "      <td>-9.127164</td>\n",
       "      <td>-0.848410</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.508230</td>\n",
       "      <td>5.304852</td>\n",
       "      <td>5.571153</td>\n",
       "      <td>5.238664</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-8.920161</td>\n",
       "      <td>1.243100</td>\n",
       "      <td>-5.785026</td>\n",
       "      <td>-7.645515</td>\n",
       "      <td>-6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.510217</td>\n",
       "      <td>-3.412284</td>\n",
       "      <td>-4.320616</td>\n",
       "      <td>-6.085435</td>\n",
       "      <td>-2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-7.221938</td>\n",
       "      <td>-4.460187</td>\n",
       "      <td>-4.915437</td>\n",
       "      <td>-7.592675</td>\n",
       "      <td>-4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-12.624729</td>\n",
       "      <td>-11.423366</td>\n",
       "      <td>-13.072220</td>\n",
       "      <td>-12.680906</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.987836</td>\n",
       "      <td>-0.367212</td>\n",
       "      <td>-0.007495</td>\n",
       "      <td>3.159029</td>\n",
       "      <td>-2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.512996</td>\n",
       "      <td>7.227273</td>\n",
       "      <td>7.968087</td>\n",
       "      <td>-1.174496</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.059953</td>\n",
       "      <td>6.875696</td>\n",
       "      <td>4.456066</td>\n",
       "      <td>3.896121</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.679958</td>\n",
       "      <td>5.464288</td>\n",
       "      <td>3.904006</td>\n",
       "      <td>1.983971</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       linreg     forest         gb         NN  Vegas Prediction\n",
       "0   -3.937607  -7.707503  -5.952967  -3.557056              -1.5\n",
       "1   -1.119679  -7.025503  -9.127164  -0.848410              -1.0\n",
       "2    6.508230   5.304852   5.571153   5.238664               4.5\n",
       "3   -8.920161   1.243100  -5.785026  -7.645515              -6.5\n",
       "4   -5.510217  -3.412284  -4.320616  -6.085435              -2.0\n",
       "5   -7.221938  -4.460187  -4.915437  -7.592675              -4.5\n",
       "6  -12.624729 -11.423366 -13.072220 -12.680906              -9.0\n",
       "7    1.987836  -0.367212  -0.007495   3.159029              -2.5\n",
       "8   -1.512996   7.227273   7.968087  -1.174496               4.0\n",
       "9    5.059953   6.875696   4.456066   3.896121               5.5\n",
       "10   1.679958   5.464288   3.904006   1.983971               2.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0caa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
